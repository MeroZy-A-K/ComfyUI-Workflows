{
  "id": "fb26a293-f736-4311-be1f-6c138b01c378",
  "revision": 0,
  "last_node_id": 65,
  "last_link_id": 102,
  "nodes": [
    {
      "id": 45,
      "type": "MarkdownNote",
      "pos": [
        -20,
        -90
      ],
      "size": [
        419.83770751953125,
        143.8331756591797
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "## üìù Inputs\n\nYour prompt goes here.  \n\nüîπ **Prompt** : The text you write to describe the image you want.  \n\nüîπ **Clip** : Translates your prompt into a **latent code** that the model can understand and use to generate the image.  \n"
      ],
      "color": "#222",
      "bgcolor": "#000"
    },
    {
      "id": 40,
      "type": "DualCLIPLoader",
      "pos": [
        -660,
        410
      ],
      "size": [
        270,
        130
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            89
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "DualCLIPLoader",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65
      },
      "widgets_values": [
        "t5xxl_fp8_e4m3fn.safetensors",
        "clip_l.safetensors",
        "flux",
        "default"
      ]
    },
    {
      "id": 8,
      "type": "VAEDecode",
      "pos": [
        1150,
        140
      ],
      "size": [
        210,
        46
      ],
      "flags": {},
      "order": 20,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 52
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 90
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [
            9
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "VAEDecode",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65
      },
      "widgets_values": []
    },
    {
      "id": 9,
      "type": "SaveImage",
      "pos": [
        1420,
        140
      ],
      "size": [
        409.6424865722656,
        456.4387512207031
      ],
      "flags": {},
      "order": 21,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 9
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "SaveImage",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65
      },
      "widgets_values": [
        "ComfyUI"
      ]
    },
    {
      "id": 42,
      "type": "LoraLoaderModelOnly",
      "pos": [
        -660,
        290
      ],
      "size": [
        270,
        82
      ],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 75
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            91
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "LoraLoaderModelOnly",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65
      },
      "widgets_values": [
        "FLUX.1-Turbo-Alpha.safetensors",
        0
      ]
    },
    {
      "id": 33,
      "type": "CLIPTextEncode",
      "pos": [
        -9.060856819152832,
        380.93914794921875
      ],
      "size": [
        422.8500061035156,
        164.30999755859375
      ],
      "flags": {
        "collapsed": true
      },
      "order": 16,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 84
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            55
          ]
        }
      ],
      "title": "CLIP Text Encode (Negative Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "CLIPTextEncode",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65
      },
      "widgets_values": [
        ""
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 6,
      "type": "CLIPTextEncode",
      "pos": [
        -10,
        110
      ],
      "size": [
        430,
        230
      ],
      "flags": {
        "collapsed": false
      },
      "order": 15,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 83
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            56
          ]
        }
      ],
      "title": "CLIP Text Encode (Positive Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "CLIPTextEncode",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65
      },
      "widgets_values": [
        "A modern residential complex featuring a row of three-story townhouses with a minimalist design, situated in a suburban setting. The facade of the buildings showcases a combination of white stucco walls and sections of light gray stone cladding, with vertical black accents that create a sleek, contemporary look. Each townhouse includes large, vertically oriented windows with black frames, providing a sense of openness and allowing natural light to flood the interiors. The roofs have private terraces with planters, adding greenery and enhancing the outdoor living space.\n\nThe ground level of each unit features a shaded entrance with recessed areas, glass doors, and small trees planted in front, contributing to a welcoming atmosphere. A low, white perimeter wall with a hedge runs along the property, separating it from the street. The surrounding landscape is lush with palm trees and other greenery, evoking a warm, tropical ambiance. The setting sun casts a soft, warm light across the scene, creating long shadows and highlighting the textures of the materials.\n\nA motion blur effect is applied to several cars driving along the street, giving a sense of movement and liveliness to the otherwise tranquil environment. Stationary cars parked along the curb are sharp and clear, contrasting with the blurred motion of the moving vehicles. The street features modern bollard lights, and the paved sidewalk in the foreground is lined with neatly trimmed grass, enhancing the clean, orderly aesthetic of the neighborhood."
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 43,
      "type": "MarkdownNote",
      "pos": [
        -1520,
        110
      ],
      "size": [
        830.6611328125,
        528.0938110351562
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "## üß© Model Loaders (Flux)  \n\nFlux models require a slightly different setup compared to SDXL. Here‚Äôs the breakdown of the main nodes used:  \n\nüîπ **Load Diffusion Model**  \n- Loads the **Flux1 Dev FP8 `.safetensors`** file.  \n- **Why this model?** It‚Äôs optimized for **fast generation** and **low VRAM usage**.  \n- **Weight Dtype** : Keep it at **default**.  \n\nüîπ **Load Lora Model Only for flux1 Turbo Alpha**  \n- Loads a **LoRA model** to modify the behavior of Flux.  \n- Example: **Flux1 Turbo Alpha `.safetensors`**.  \n- **Why use it?** This LoRA allows **much faster generation** ‚Äî only **8 steps** needed instead of 20 (affact the quality se be aware while using it).  \n\nüîπ **DualCLIPLoader**  \nFlux requires **two CLIP text encoders** for prompts:  \n1. **`t5xxl_fp8_e4m3fn.safetensors`** ‚Üí Handles **long, complex text prompts** with better understanding.  \n2. **`clip_i.safetensors`** ‚Üí Focused on **fine-tuning style and detail alignment** with the model.  \n- In the node, set **Type** ‚Üí `flux`.  \n\nüîπ **Load VAE**  \n- Loads the **`ae.safetensors`** file.  \n- **What it does?** The VAE compresses images into **latent codes** (for the model to process) and then decodes them back into the final image.  \n- Controls **color accuracy** and **detail recovery** in the output.  \n\n---\n### Recommended Image Dimensions\n- 1344 x 768 (16:9)\n- 1024 x 1024 (square)\n- 832 x 1216 (landscape/ portrait)\n\n\n### ‚ö° VRAM Recommendations  \n- **6‚Äì8 GB GPUs** ‚Üí Use **Flux1 Dev FP8** with Turbo LoRA for **fast, low-VRAM generation**.  \n- **12 GB+ GPUs** ‚Üí You can switch to **full precision models** (no FP8 compression) for **slightly better quality**, but they use more VRAM.  \n- **Turbo LoRA** is highly recommended regardless of VRAM since it reduces steps (8 instead of 20) and speeds up iteration.  \n"
      ],
      "color": "#222",
      "bgcolor": "#000"
    },
    {
      "id": 38,
      "type": "UNETLoader",
      "pos": [
        -660,
        160
      ],
      "size": [
        270,
        82
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            75
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "UNETLoader",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65
      },
      "widgets_values": [
        "flux1-dev-fp8.safetensors",
        "default"
      ]
    },
    {
      "id": 51,
      "type": "LoraLoader",
      "pos": [
        -340,
        150
      ],
      "size": [
        270,
        126
      ],
      "flags": {},
      "order": 13,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 91
        },
        {
          "name": "clip",
          "type": "CLIP",
          "link": 89
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            78
          ]
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            82
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "LoraLoader",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65
      },
      "widgets_values": [
        "flux-arch-realism-lora_v2.safetensors",
        0.8,
        0.8
      ]
    },
    {
      "id": 52,
      "type": "LoraLoader",
      "pos": [
        -340,
        330
      ],
      "size": [
        270,
        126
      ],
      "flags": {},
      "order": 14,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 78
        },
        {
          "name": "clip",
          "type": "CLIP",
          "link": 82
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            79
          ]
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            83,
            84
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "LoraLoader",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65
      },
      "widgets_values": [
        "design-input_archviz_v01.safetensors",
        1,
        1
      ]
    },
    {
      "id": 39,
      "type": "VAELoader",
      "pos": [
        -660,
        580
      ],
      "size": [
        270,
        58
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "slot_index": 0,
          "links": [
            90
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "VAELoader",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65
      },
      "widgets_values": [
        "ae.safetensors"
      ]
    },
    {
      "id": 59,
      "type": "StyleModelLoader",
      "pos": [
        490,
        -560
      ],
      "size": [
        311.82000732421875,
        60
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "STYLE_MODEL",
          "type": "STYLE_MODEL",
          "links": [
            98
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.44",
        "Node name for S&R": "StyleModelLoader",
        "models": [
          {
            "name": "flux1-redux-dev.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Flux1-Redux-Dev/resolve/main/flux1-redux-dev.safetensors",
            "directory": "style_models"
          }
        ]
      },
      "widgets_values": [
        "flux1-redux-dev.safetensors"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 61,
      "type": "CLIPVisionEncode",
      "pos": [
        870,
        -650
      ],
      "size": [
        300,
        80
      ],
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "clip_vision",
          "type": "CLIP_VISION",
          "link": 96
        },
        {
          "name": "image",
          "type": "IMAGE",
          "link": 97
        }
      ],
      "outputs": [
        {
          "name": "CLIP_VISION_OUTPUT",
          "type": "CLIP_VISION_OUTPUT",
          "slot_index": 0,
          "links": [
            99
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.44",
        "Node name for S&R": "CLIPVisionEncode"
      },
      "widgets_values": [
        "center"
      ]
    },
    {
      "id": 60,
      "type": "CLIPVisionLoader",
      "pos": [
        490,
        -660
      ],
      "size": [
        311.82000732421875,
        60
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP_VISION",
          "type": "CLIP_VISION",
          "slot_index": 0,
          "links": [
            96
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.44",
        "Node name for S&R": "CLIPVisionLoader",
        "models": [
          {
            "name": "sigclip_vision_patch14_384.safetensors",
            "url": "https://huggingface.co/Comfy-Org/sigclip_vision_384/resolve/main/sigclip_vision_patch14_384.safetensors?download=true",
            "directory": "clip_vision"
          }
        ]
      },
      "widgets_values": [
        "sigclip_vision_patch14_384.safetensors"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 35,
      "type": "FluxGuidance",
      "pos": [
        465.12506103515625,
        128.4875030517578
      ],
      "size": [
        211.60000610351562,
        58
      ],
      "flags": {},
      "order": 17,
      "mode": 0,
      "inputs": [
        {
          "name": "conditioning",
          "type": "CONDITIONING",
          "link": 56
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            100
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "FluxGuidance",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65
      },
      "widgets_values": [
        3.5
      ]
    },
    {
      "id": 64,
      "type": "EmptySD3LatentImage",
      "pos": [
        463.0942687988281,
        235.96636962890625
      ],
      "size": [
        315,
        106
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            102
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "EmptySD3LatentImage",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65
      },
      "widgets_values": [
        1024,
        1024,
        1
      ]
    },
    {
      "id": 53,
      "type": "MarkdownNote",
      "pos": [
        460,
        -90
      ],
      "size": [
        900,
        150
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "## ‚öôÔ∏è Config & Processing (Flux)  \n\nConfiguration settings for sampling with Flux models.  \n\nüîπ **EmptySD3 Latent Image** : Creates a blank latent canvas (blank image) **sized for Flux/SD3 models**.  \n- Unlike the standard **Empty Latent Image**, this one is optimized for Flux and SD3 architecture.  \n- **Width / Height** : Defines the resolution of the output image.  \n- **Batch Size** : Number of images generated in one run.  \n\nüîπ **K Sampler** : The core sampling process ‚Äî it transforms latent noise into a structured image.  \n- **Model** : Connect your **Flux diffusion model**.  \n- **Positive Prompt** : Encoded text from CLIP with what you *want* to see.  \n- **Negative Prompt** : Must be **empty** in Flux (ignored by the model).  \n- **Latent Image** : Connect from **EmptySD3 Latent Image**.  \n- **Seed** : Controls randomness (same seed = repeatable results).  \n- **Steps** : Number of iterations.  \n  - With **Turbo LoRA**: **8 steps** is usually enough.  \n  - Without Turbo: **20 steps** for stable results.  \n- **CFG (Classifier-Free Guidance)** :  \n  - For Flux, this must be set to **1**.  \n  - Why? Because Flux handles guidance differently ‚Äî CFG above 1 can actually break image quality.  \n- **Sampler Method** : Algorithm used for sampling (**Euler, DPM++**, etc.) ‚Äì does not drastically change results.  \n\nüîπ **Flux Guidance** : A special node required for Flux models.  \n- Controls how strongly the prompt influences generation.  \n- **Recommended Values**:  \n  - **3.5** ‚Üí Strong guidance (more faithful to prompt).  \n  - **2.5** ‚Üí Softer guidance (more freedom/creativity).  \n\nüîπ **VAE Decode** : Converts the processed latent back into a final image.  \n- **Samples** : The latent output from **K Sampler**.  \n- **VAE** : The **Variational Autoencoder** (decodes latents back into pixels).  \n\n"
      ],
      "color": "#222",
      "bgcolor": "#000"
    },
    {
      "id": 65,
      "type": "MarkdownNote",
      "pos": [
        470,
        -1240
      ],
      "size": [
        720,
        480
      ],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "### **üîπ Apply Flux Redux**\n\nFlux Redux is an adapter model specifically designed for generating image variants. It can generate variants in a similar style based on the input image without the need for text prompts.\n\n---\n\n### **üîπ Required Model Loaders**\n\n- **Load CLIP Vision** ‚Üí Use `sigclip_vision_patch14_384.safetensors`.  \n- **Load Style Model** ‚Üí Load the **Flux Redux** style model.  \n\n---\n\n### **üîπ Encoding Reference Image**\n\n- Use **CLIP Vision Encode** to process the reference image.  \n- This creates an embedding of the reference style, which will later be blended with your prompt conditioning.  \n\n---\n\n### **üîπ Main Node: Apply Style Model**\n\nInputs:  \n1. **Conditioning** ‚Üí From your **prompt** processed through **Flux Guidance Conditioning**.  \n2. **Style Model** ‚Üí Loaded Flux Redux style model.  \n3. **CLIP Vision Encode** ‚Üí The encoded reference image.  \n\nParameters:  \n- **Strength (0 ‚Üí 1)** ‚Üí Controls how strongly the style is applied.  \n  - **0.3 ‚Äì 0.5** = Subtle style influence.  \n  - **0.6 ‚Äì 0.8** = Stronger style transfer.  \n- **Type** ‚Üí Default is **Multiply** (how the style combines with prompt conditioning).  \n\nOutput:\n\n- The node outputs **Conditioning** that combines prompt + style.  \n- Connect this back into the **K Sampler** as the **positive conditioning**.  \n"
      ],
      "color": "#222",
      "bgcolor": "#000"
    },
    {
      "id": 63,
      "type": "LoadImage",
      "pos": [
        480,
        -450
      ],
      "size": [
        310,
        314
      ],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            97
          ]
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.44",
        "Node name for S&R": "LoadImage"
      },
      "widgets_values": [
        "ComfyUI_00233_.png",
        "image"
      ]
    },
    {
      "id": 62,
      "type": "StyleModelApply",
      "pos": [
        870,
        -500
      ],
      "size": [
        300,
        122
      ],
      "flags": {},
      "order": 18,
      "mode": 0,
      "inputs": [
        {
          "name": "conditioning",
          "type": "CONDITIONING",
          "link": 100
        },
        {
          "name": "style_model",
          "type": "STYLE_MODEL",
          "link": 98
        },
        {
          "name": "clip_vision_output",
          "type": "CLIP_VISION_OUTPUT",
          "link": 99
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            101
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.44",
        "Node name for S&R": "StyleModelApply"
      },
      "widgets_values": [
        1,
        "multiply"
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 31,
      "type": "KSampler",
      "pos": [
        820,
        140
      ],
      "size": [
        315,
        474
      ],
      "flags": {},
      "order": 19,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 79
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 101
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 55
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 102
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            52
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "KSampler",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65
      },
      "widgets_values": [
        183764702453344,
        "randomize",
        20,
        1,
        "euler",
        "simple",
        1
      ]
    }
  ],
  "links": [
    [
      9,
      8,
      0,
      9,
      0,
      "IMAGE"
    ],
    [
      52,
      31,
      0,
      8,
      0,
      "LATENT"
    ],
    [
      55,
      33,
      0,
      31,
      2,
      "CONDITIONING"
    ],
    [
      56,
      6,
      0,
      35,
      0,
      "CONDITIONING"
    ],
    [
      75,
      38,
      0,
      42,
      0,
      "MODEL"
    ],
    [
      78,
      51,
      0,
      52,
      0,
      "MODEL"
    ],
    [
      79,
      52,
      0,
      31,
      0,
      "MODEL"
    ],
    [
      82,
      51,
      1,
      52,
      1,
      "CLIP"
    ],
    [
      83,
      52,
      1,
      6,
      0,
      "CLIP"
    ],
    [
      84,
      52,
      1,
      33,
      0,
      "CLIP"
    ],
    [
      89,
      40,
      0,
      51,
      1,
      "CLIP"
    ],
    [
      90,
      39,
      0,
      8,
      1,
      "VAE"
    ],
    [
      91,
      42,
      0,
      51,
      0,
      "MODEL"
    ],
    [
      96,
      60,
      0,
      61,
      0,
      "CLIP_VISION"
    ],
    [
      97,
      63,
      0,
      61,
      1,
      "IMAGE"
    ],
    [
      98,
      59,
      0,
      62,
      1,
      "STYLE_MODEL"
    ],
    [
      99,
      61,
      0,
      62,
      2,
      "CLIP_VISION_OUTPUT"
    ],
    [
      100,
      35,
      0,
      62,
      0,
      "CONDITIONING"
    ],
    [
      101,
      62,
      0,
      31,
      1,
      "CONDITIONING"
    ],
    [
      102,
      64,
      0,
      31,
      3,
      "LATENT"
    ]
  ],
  "groups": [
    {
      "id": 1,
      "title": "Flux Model Loader",
      "bounding": [
        -670,
        80,
        290,
        561.5999755859375
      ],
      "color": "#A88",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 2,
      "title": "LoRA loader",
      "bounding": [
        -350,
        80,
        293.1131591796875,
        389.4425354003906
      ],
      "color": "#A88",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 3,
      "title": "Apply Flux Redux",
      "bounding": [
        470,
        -740,
        720,
        610
      ],
      "color": "#a1309b",
      "font_size": 24,
      "flags": {}
    }
  ],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.6830134553650705,
      "offset": [
        770.7097259772573,
        795.7701812879102
      ]
    },
    "frontendVersion": "1.26.11",
    "ue_links": [],
    "VHS_latentpreview": false,
    "VHS_latentpreviewrate": 0,
    "VHS_MetadataImage": true,
    "VHS_KeepIntermediate": true
  },
  "version": 0.4
}